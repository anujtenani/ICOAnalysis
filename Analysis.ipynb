{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnalysis on how the ownership of a token holder change\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Analysis on how the ownership of a token holder change\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import pandas\n",
    "import numpy\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS Start!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/usr/local/lib/python2.7/site-packages/urllib3/connectionpool.py:852: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EOS Finished!\n"
     ]
    }
   ],
   "source": [
    "#the base url for etherscan\n",
    "baseUrl='https://etherscan.io/'\n",
    "#the connection pool\n",
    "pool=urllib3.PoolManager()\n",
    "def html_convert_top100(tokenid, classname):\n",
    "    '''\n",
    "    Get the top 100 owners of the coin\n",
    "    '''\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    funUrl_chart='token/tokenholderchart/'\n",
    "    r=pool.request('GET',baseUrl+funUrl_chart+tokenid)\n",
    "    html=r.data\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find(\"table\", attrs=classname)\n",
    "    headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "    for idx in range(len(headings)):\n",
    "        headings[idx]=str(headings[idx])\n",
    "    datasets = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "        ls=list(dataset)\n",
    "        datasets.append(ls)\n",
    "\n",
    "    '''\n",
    "    Clean the data\n",
    "    '''\n",
    "    for idx in range(len(datasets)):\n",
    "        for idxx in range(len(datasets[idx])):\n",
    "            tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "            tmp=tmp.strip()\n",
    "            tmp=str(tmp)\n",
    "            datasets[idx][idxx]=tmp\n",
    "\n",
    "    '''\n",
    "    Create pandas dataframe and convert it to float\n",
    "    '''\n",
    "    df=pandas.DataFrame(datasets, columns=headings)\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].str.replace(',','')\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].astype(numpy.float64)\n",
    "    df['Percentage']=df['Percentage'].str.strip('%')\n",
    "    df['Percentage']=df['Percentage'].astype(numpy.float64)/100\n",
    "    return df\n",
    "\n",
    "def owners_tr(ownerid, tokenname, classname):\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    transUrl='tokentxns?a='\n",
    "    nextlinks=[]\n",
    "    nextlinks.append(transUrl+ownerid)\n",
    "    '''\n",
    "    trans_dic={\n",
    "        tx:{\n",
    "            Value:'', \n",
    "            Block:''\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    trans_dic={}\n",
    "    print tokenname+\" Start!\"\n",
    "    while len(nextlinks)>0:\n",
    "        link=nextlinks.pop()\n",
    "        r=pool.request('GET',baseUrl+link)\n",
    "        html=r.data\n",
    "        soup = BeautifulSoup(html)\n",
    "        '''\n",
    "        Get the next link\n",
    "        '''\n",
    "        a_tag=soup.find_all('a', id=\"ContentPlaceHolder1_HyperLinkNext\",href=True)\n",
    "        if a_tag[0]['href']!='#':\n",
    "            next_link=a_tag[0]['href']\n",
    "            nextlinks.append(next_link)\n",
    "        table = soup.find(\"table\", attrs=classname)\n",
    "        headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "        for idx in range(len(headings)):\n",
    "            headings[idx]=str(headings[idx])\n",
    "            if headings[idx]=='':\n",
    "                headings[idx]='direction'\n",
    "        datasets = []\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "            ls=list(dataset)\n",
    "            datasets.append(ls)\n",
    "        '''\n",
    "        Clean the data\n",
    "        '''\n",
    "        for idx in range(len(datasets)):\n",
    "            for idxx in range(len(datasets[idx])):\n",
    "                tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "                tmp=tmp.strip()\n",
    "                tmp=str(tmp)\n",
    "                datasets[idx][idxx]=tmp\n",
    "        '''\n",
    "        Create pandas dataframe and convert it to float\n",
    "        '''\n",
    "        df=pandas.DataFrame(datasets, columns=headings)\n",
    "        df['Token']=df['Token'].str.upper()\n",
    "        df=df.loc[df['Token'] == tokenname]\n",
    "        df['Value']=df['Value'].str.replace(',','')\n",
    "        df['Value']=df['Value'].astype(numpy.float64)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Value']!=0:\n",
    "                if row['direction'] == 'OUT':\n",
    "                    val=-row['Value']\n",
    "                else:\n",
    "                    val=row['Value']\n",
    "                trans_dic[row['TxHash']]={}\n",
    "                trans_dic[row['TxHash']]['Value']=val\n",
    "        \n",
    "        txurl='tx/'\n",
    "        for tx in trans_dic:\n",
    "            block=''\n",
    "            req=pool.request('GET',baseUrl+txurl+tx)\n",
    "            html_tx=req.data\n",
    "            tx_soup=BeautifulSoup(html_tx)\n",
    "            tx_a_tag=tx_soup.find_all('a',href=True)\n",
    "            for tag in tx_a_tag:\n",
    "                if '/block/' in tag['href']:\n",
    "                    block=str(tag.getText())\n",
    "                    trans_dic[tx]['Block']=block\n",
    "        #set a lag here so the server won't kick us out\n",
    "        sleep(0.001)\n",
    "    print tokenname+\" Finished!\"\n",
    "    return trans_dic\n",
    "\n",
    "def ICO_TOKEN(tokenid, tokenname):\n",
    "\n",
    "    df=html_convert_top100(tokenid, \"table table-hover \")\n",
    "    '''\n",
    "    Construct the ownership table\n",
    "    '''\n",
    "    owners={}\n",
    "    for index, row in df.iterrows():\n",
    "        owners[row['Address']]=row['Quantity (Token)']\n",
    "    '''\n",
    "    Construct the ownership transaction table\n",
    "    '''\n",
    "    trans_history=owners_tr(\"0x0862afd90666944a0b6be91aa6364afc134969a2\",tokenname, 'table table-hover ')\n",
    "        \n",
    "ICO_TOKEN('0x55228583b7b41e138d7129bb81714dc6f739ec22','EOS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
