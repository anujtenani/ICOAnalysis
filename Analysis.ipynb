{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Analysis on how the ownership of a token holder change\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import re\n",
    "import pandas\n",
    "import numpy\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#the base url for etherscan\n",
    "baseUrl='https://etherscan.io/'\n",
    "#the connection pool\n",
    "pool=urllib3.PoolManager()\n",
    "def html_convert_top100(tokenid, classname):\n",
    "    '''\n",
    "    Get the top 100 owners of the coin\n",
    "    '''\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    funUrl_chart='token/tokenholderchart/'\n",
    "    r=pool.request('GET',baseUrl+funUrl_chart+tokenid)\n",
    "    html=r.data\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find(\"table\", attrs=classname)\n",
    "    headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "    for idx in range(len(headings)):\n",
    "        headings[idx]=str(headings[idx])\n",
    "    datasets = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "        ls=list(dataset)\n",
    "        datasets.append(ls)\n",
    "\n",
    "    '''\n",
    "    Clean the data\n",
    "    '''\n",
    "    for idx in range(len(datasets)):\n",
    "        for idxx in range(len(datasets[idx])):\n",
    "            tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "            tmp=tmp.strip()\n",
    "            tmp=str(tmp)\n",
    "            datasets[idx][idxx]=tmp\n",
    "\n",
    "    '''\n",
    "    Create pandas dataframe and convert it to float\n",
    "    '''\n",
    "    df=pandas.DataFrame(datasets, columns=headings)\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].str.replace(',','')\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].astype(numpy.float64)\n",
    "    df['Percentage']=df['Percentage'].str.strip('%')\n",
    "    df['Percentage']=df['Percentage'].astype(numpy.float64)/100\n",
    "    return df\n",
    "\n",
    "def owners_tr(ownerid, tokenname, classname):\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    transUrl='tokentxns?a='\n",
    "    nextlinks=[]\n",
    "    nextlinks.append(transUrl+ownerid)\n",
    "    '''\n",
    "    trans_dic={\n",
    "        tx:{\n",
    "            Value:'', \n",
    "            Block:''\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    trans_dic={}\n",
    "    i=1\n",
    "    while len(nextlinks)>0:\n",
    "        print \"processing page \"+str(i)+\" of owner\"+ownerid\n",
    "        link=nextlinks.pop()\n",
    "        r=pool.request('GET',baseUrl+link)\n",
    "        html=r.data\n",
    "        soup = BeautifulSoup(html)\n",
    "        '''\n",
    "        Get the next link\n",
    "        '''\n",
    "        a_tag=soup.find_all('a', id=\"ContentPlaceHolder1_HyperLinkNext\",href=True)\n",
    "        if a_tag[0]['href']!='#':\n",
    "            next_link=a_tag[0]['href']\n",
    "            nextlinks.append(next_link)\n",
    "        table = soup.find(\"table\", attrs=classname)\n",
    "        headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "        for idx in range(len(headings)):\n",
    "            headings[idx]=str(headings[idx])\n",
    "            if headings[idx]=='':\n",
    "                headings[idx]='direction'\n",
    "        datasets = []\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "            ls=list(dataset)\n",
    "            datasets.append(ls)\n",
    "        '''\n",
    "        Clean the data\n",
    "        '''\n",
    "        for idx in range(len(datasets)):\n",
    "            for idxx in range(len(datasets[idx])):\n",
    "                tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "                tmp=tmp.strip()\n",
    "                tmp=str(tmp)\n",
    "                datasets[idx][idxx]=tmp\n",
    "        '''\n",
    "        Create pandas dataframe and convert it to float\n",
    "        '''\n",
    "        df=pandas.DataFrame(datasets, columns=headings)\n",
    "        df['Token']=df['Token'].str.upper()\n",
    "        df=df.loc[df['Token'] == tokenname]\n",
    "        df['Value']=df['Value'].str.replace(',','')\n",
    "        df['Value']=df['Value'].astype(numpy.float64)\n",
    "        for index, row in df.iterrows():\n",
    "            if row['Value']!=0:\n",
    "                if row['direction'] == 'OUT':\n",
    "                    val=-row['Value']\n",
    "                else:\n",
    "                    val=row['Value']\n",
    "                trans_dic[row['TxHash']]={}\n",
    "                trans_dic[row['TxHash']]['Value']=val\n",
    "        \n",
    "        txurl='tx/'\n",
    "        for tx in trans_dic:\n",
    "            block=''\n",
    "            req=pool.request('GET',baseUrl+txurl+tx)\n",
    "            html_tx=req.data\n",
    "            tx_soup=BeautifulSoup(html_tx)\n",
    "            tx_a_tag=tx_soup.find_all('a',href=True)\n",
    "            for tag in tx_a_tag:\n",
    "                if '/block/' in tag['href']:\n",
    "                    block=str(tag.getText())\n",
    "                    trans_dic[tx]['Block']=block\n",
    "        i=i+1\n",
    "        #set a lag here to reduce CPU pressure\n",
    "        sleep(0.001)\n",
    "    return trans_dic\n",
    "\n",
    "def ICO_TOKEN(tokenid, tokenname):\n",
    "\n",
    "    df=html_convert_top100(tokenid, \"table table-hover \")\n",
    "    '''\n",
    "    Construct the ownership table\n",
    "    '''\n",
    "    owners={}\n",
    "    for index, row in df.iterrows():\n",
    "        owners[row['Address']]=row['Quantity (Token)']\n",
    "    print owners\n",
    "    '''\n",
    "    Construct the ownership transaction table\n",
    "    '''\n",
    "    trans_history={}\n",
    "    for owner in owners:\n",
    "        trans_history[owner]=owners_tr(owner,tokenname, 'table table-hover ')\n",
    "    \n",
    "    '''\n",
    "    Backout the transaction history\n",
    "    '''\n",
    "    headtable=['Block Height', 'Owner', 'TransactionID', 'TOKEN', 'BALANCE']\n",
    "    content=[]\n",
    "    o=1\n",
    "    for owner in owners:\n",
    "        print \"processing owner \"+str(o)+\" there are total \"+len(owners)+\" owners\"\n",
    "        balance=owners[owner]\n",
    "        trans=trans_history[owner]\n",
    "        for t in trans:\n",
    "            entry=[]\n",
    "            #transaction ID\n",
    "            TID=t\n",
    "            #Block Height\n",
    "            Block=trans[t]['Block']\n",
    "            balance=balance-trans[t]['Value']\n",
    "            entry.append(Block)\n",
    "            entry.append(owner)\n",
    "            entry.append(TID)\n",
    "            entry.append(tokenname)\n",
    "            entry.append(balance)\n",
    "            content.append(entry)\n",
    "        o=o+1\n",
    "    dataframe=pandas.DataFrame(content, columns=headtable)\n",
    "    return dataframe\n",
    "    \n",
    "datahistory=ICO_TOKEN('0x86fa049857e0209aa7d9e616f7eb3b3b78ecfdb0','EOS')\n",
    "datahistory.to_csv('top100.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
