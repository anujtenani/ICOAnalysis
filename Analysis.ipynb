{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Analysis on how the ownership of a token holder change\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "#disable the annoying security warnings\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import re\n",
    "import pandas\n",
    "import numpy\n",
    "from time import sleep\n",
    "import time\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#the base url for etherscan\n",
    "baseUrl='https://etherscan.io/'\n",
    "#the connection pool, making 10 connections\n",
    "pool=urllib3.PoolManager(10)\n",
    "#number of threads\n",
    "numthread=8\n",
    "def html_convert_top100(tokenid, classname):\n",
    "    '''\n",
    "    Get the top 100 owners of the coin\n",
    "    '''\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    funUrl_chart='token/tokenholderchart/'\n",
    "    r=pool.request('GET',baseUrl+funUrl_chart+tokenid)\n",
    "    html=r.data\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find(\"table\", attrs=classname)\n",
    "    headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "    for idx in range(len(headings)):\n",
    "        headings[idx]=str(headings[idx])\n",
    "    datasets = []\n",
    "    for row in table.find_all(\"tr\")[1:]:\n",
    "        dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "        ls=list(dataset)\n",
    "        datasets.append(ls)\n",
    "\n",
    "    '''\n",
    "    Clean the data\n",
    "    '''\n",
    "    for idx in range(len(datasets)):\n",
    "        for idxx in range(len(datasets[idx])):\n",
    "            tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "            tmp=tmp.strip()\n",
    "            tmp=str(tmp)\n",
    "            datasets[idx][idxx]=tmp\n",
    "\n",
    "    '''\n",
    "    Create pandas dataframe and convert it to float\n",
    "    '''\n",
    "    df=pandas.DataFrame(datasets, columns=headings)\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].str.replace(',','')\n",
    "    df['Quantity (Token)']=df['Quantity (Token)'].astype(numpy.float64)\n",
    "    df['Percentage']=df['Percentage'].str.strip('%')\n",
    "    df['Percentage']=df['Percentage'].astype(numpy.float64)/100\n",
    "    return df\n",
    "\n",
    "def owners_tr(ownerid, tokenname, classname):\n",
    "    global baseUrl\n",
    "    global pool\n",
    "    transUrl='tokentxns?a='\n",
    "    nextlinks=[]\n",
    "    nextlinks.append(transUrl+ownerid)\n",
    "    '''\n",
    "    trans_dic=[\n",
    "        tx:{\n",
    "            Value:'', \n",
    "            Block:''\n",
    "        }\n",
    "    ]\n",
    "    '''\n",
    "    trans_dic=[]\n",
    "    i=1\n",
    "    while len(nextlinks)>0:\n",
    "        starttime=time.time()\n",
    "        print \"processing page \"+str(i)+\" of owner\"+ownerid\n",
    "        link=nextlinks.pop()\n",
    "        r=pool.request('GET',baseUrl+link)\n",
    "        html=r.data\n",
    "        soup = BeautifulSoup(html)\n",
    "        '''\n",
    "        Get the next link\n",
    "        '''\n",
    "        a_tag=soup.find_all('a', id=\"ContentPlaceHolder1_HyperLinkNext\",href=True)\n",
    "        if a_tag[0]['href']!='#':\n",
    "            next_link=a_tag[0]['href']\n",
    "            nextlinks.append(next_link)\n",
    "        table = soup.find(\"table\", attrs=classname)\n",
    "        headings = [th.get_text() for th in table.find(\"tr\").find_all(\"th\")]\n",
    "        for idx in range(len(headings)):\n",
    "            headings[idx]=str(headings[idx])\n",
    "            if headings[idx]=='':\n",
    "                headings[idx]='direction'\n",
    "        datasets = []\n",
    "        for row in table.find_all(\"tr\")[1:]:\n",
    "            dataset = (td.get_text() for td in row.find_all(\"td\"))\n",
    "            ls=list(dataset)\n",
    "            datasets.append(ls)\n",
    "        '''\n",
    "        Clean the data\n",
    "        '''\n",
    "        for idx in range(len(datasets)):\n",
    "            for idxx in range(len(datasets[idx])):\n",
    "                tmp=re.sub(r'\\([^)]*\\)', '', datasets[idx][idxx])\n",
    "                tmp=tmp.strip()\n",
    "                tmp=str(tmp)\n",
    "                datasets[idx][idxx]=tmp\n",
    "        '''\n",
    "        Create pandas dataframe and convert it to float\n",
    "        '''\n",
    "        df=pandas.DataFrame(datasets, columns=headings)\n",
    "        df['Token']=df['Token'].str.upper()\n",
    "        df=df.loc[df['Token'] == tokenname]\n",
    "        df['Value']=df['Value'].str.replace(',','')\n",
    "        df['Value']=df['Value'].astype(numpy.float64)\n",
    "        for index, row in df.iterrows():\n",
    "            tmp_dic={}\n",
    "            if row['Value']!=0:\n",
    "                if row['direction'] == 'OUT':\n",
    "                    val=-row['Value']\n",
    "                else:\n",
    "                    val=row['Value']\n",
    "                tx=row['TxHash']\n",
    "                tmp_dic[tx]={}\n",
    "                tmp_dic[tx]['Value']=val\n",
    "                '''\n",
    "                Now, get the block number\n",
    "                '''\n",
    "                txurl='tx/'\n",
    "                block=''\n",
    "                req=pool.request('GET',baseUrl+txurl+tx)\n",
    "                html_tx=req.data\n",
    "                tx_soup=BeautifulSoup(html_tx)\n",
    "                tx_a_tag=tx_soup.find_all('a',href=True)\n",
    "                for tag in tx_a_tag:\n",
    "                    if '/block/' in tag['href']:\n",
    "                        block=str(tag.getText())\n",
    "                        tmp_dic[tx]['Block']=block\n",
    "                trans_dic.append(tmp_dic)\n",
    "        i=i+1\n",
    "        elapsed=time.time()-starttime\n",
    "        print str(elapsed)+\" second for each request\"\n",
    "    return trans_dic\n",
    "\n",
    "def tr_wrapper(args):\n",
    "    tokenname=args[0]\n",
    "    owners=args[1]\n",
    "    '''\n",
    "    Construct the ownership transaction table\n",
    "    '''\n",
    "    trans_history={}\n",
    "    for owner in owners:\n",
    "        trans_history[owner]=owners_tr(owner,tokenname, 'table table-hover ')\n",
    "    '''\n",
    "    Backout the transaction history\n",
    "    '''\n",
    "    headtable=['Block Height', 'Owner', 'TransactionID', 'TOKEN', 'BALANCE']\n",
    "    for owner in owners:\n",
    "        content=[]\n",
    "        balance=owners[owner]\n",
    "        print balance\n",
    "        trans=trans_history[owner]\n",
    "        for l in trans:\n",
    "            for t in l:\n",
    "                entry=[]\n",
    "                #transaction ID\n",
    "                TID=t\n",
    "                #Block Height\n",
    "                Block=l[t]['Block']\n",
    "                entry.append(Block)\n",
    "                entry.append(owner)\n",
    "                entry.append(TID)\n",
    "                entry.append(tokenname)\n",
    "                entry.append(balance)\n",
    "                content.append(entry)\n",
    "                balance=balance-l[t]['Value']\n",
    "        dataframe=pandas.DataFrame(content, columns=headtable)\n",
    "        dataframe.to_csv('./csv/'+owner+'top100.csv')\n",
    "     \n",
    "\n",
    "def ICO_TOKEN(tokenid, tokenname):\n",
    "    global numthread\n",
    "    df=html_convert_top100(tokenid, \"table table-hover \")\n",
    "    '''\n",
    "    Construct the ownership table\n",
    "    '''\n",
    "    owners={}\n",
    "    for index, row in df.iterrows():\n",
    "        owners[row['Address']]=row['Quantity (Token)']\n",
    "    owner_list=[] \n",
    "    for key in owners:\n",
    "        tmp_dict={}\n",
    "        tmp_dict[key]=owners[key]\n",
    "        owner_list.append(tmp_dict)\n",
    "    # make the Pool of workers\n",
    "    print \"starting \"+str(numthread)+\" threads...\" \n",
    "    tpool = ThreadPool(numthread)\n",
    "    tpool.map(tr_wrapper, itertools.izip(itertools.repeat(tokenname), owner_list))\n",
    "    tpool.close()\n",
    "    tpool.join()\n",
    "    \n",
    "ICO_TOKEN('0x86Fa049857E0209aa7D9e616F7eb3b3B78ECfdb0','EOS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
